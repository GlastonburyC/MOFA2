<!DOCTYPE html>
<html lang="en-US">
  <head>

    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>FAQ | Multi-Omics Factor Analysis (MOFA+)</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="FAQ" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Multi-Omics Factor Analysis V2 (MOFA+)" />
<meta property="og:description" content="Multi-Omics Factor Analysis V2 (MOFA+)" />
<link rel="canonical" href="http://localhost:4000/faq.html" />
<meta property="og:url" content="http://localhost:4000/faq.html" />
<meta property="og:site_name" content="Multi-Omics Factor Analysis (MOFA+)" />
<script type="application/ld+json">
{"headline":"FAQ","description":"Multi-Omics Factor Analysis V2 (MOFA+)","@type":"WebPage","url":"http://localhost:4000/faq.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=33b8e818418c8e3e88668fb03d1d52bc031c390a">
  </head>
  <body>
    <!-- <a id="skip-to-content" href="#content">Skip to the content.</a> -->

    <header class="page-header" role="banner">
      <h1 class="project-name">FAQ</h1>
      <h2 class="project-tagline">Multi-Omics Factor Analysis V2 (MOFA+)</h2>

      <a href="index.html" class="btn">Home</a>
      <a href="installation.html" class="btn">Installation</a>
      <a href="tutorials.html" class="btn">Tutorials</a>
      <a href="http://www.ebi.ac.uk/shiny/mofa/" class="btn">Interactive web server</a>
      <a href="faq.html" class="btn">FAQ</a>
      <a href="contact.html" class="btn">Contact</a>
      
        <a href="https://github.com/bioFAM/MOFA2" class="btn">View on GitHub</a>
      
    </header>

    <main id="content" class="main-content" role="main">
      <h2 id="faq-on-the-transition-from-mofa-to-mofa">FAQ on the transition from MOFA to MOFA+</h2>

<p><strong>Can MOFA+ be applied to bulk data?</strong><br />
MOFA+ remains 100% applicable to bulk data.</p>

<p><strong>Does MOFA+ inherit previous features from MOFA v1?</strong><br />
Yes, pretty much everything: handling of missing data, non-gaussian likelihoods and sparsity in the weights.</p>

<p><strong>Do I need to provide multiple groups to use MOFA+?</strong><br />
No. Unless provided, MOFA+ assumes that you do not have multi-group structure in your data.</p>

<h2 id="faq-on-the-downstream-analysis">FAQ on the downstream analysis</h2>

<p><strong>How do I interpret the factors?</strong><br />
The MOFA factors capture the global sources of variability in the data. Mathematically, each factor ordinates cells along a one-dimensional axis centered at zero. The value per se is not interpretable, only the relative positioning of samples is important. Samples with different signs manifest opposite “effects” along the inferred axis of variation, with higher absolute value indicating a stronger effect. Note that the interpretation of factors is analogous to the interpretation of the principal components in PCA.</p>

<p><strong>How do I interpret the weights?</strong><br />
The weights provide a score for how strong each feature relates to each factor, hence allowing a biological interpretation of the latent factors. Features with no as- sociation with the factor have values close to zero, while genes with strong association with the factor have large absolute values. The sign of the weight indicates the direction of the effect: a positive weight indicates that the feature has higher levels in the cells with positive factor values, and vice versa.</p>

<!-- **How can I do Gene Set Enrichment Analysis?**  
This is explained in the [GSEA vignette](https://raw.githack.com/bioFAM/MOFA2/master/MOFA2/vignettes/GSEA.html) -->

<!-- **How can I assess the robustness of factors?** 
A procedure that can be applied to evaluate the robustness of factors is to downsample the number of samples and/or the number of features and inspect if the factors are consistently found. However, keep in mind that there could be cases where the full data set is required to detect small yet important sources of variation. Hence, lack of robustness under downsampling does not necessarily imply that a factor is not biologically meaningful. -->

<h2 id="faq-on-the-data-processing">FAQ on the data processing</h2>

<p><strong>How do I normalise the data?</strong><br />
Proper normalisation is critical for the model to work. First, one needs to remove library size effects. For count-based data such as RNA-seq or ATAC-seq we recommend size factor normalisation + variance stabilisation. If this is not done correctly, the model will learn a very strong Factor 1 that will capture differences in the <em>total</em> expression per sample, and more subtle sources of variation will be downweighted.</p>

<p><strong>Should I do any filtering to the input data?</strong><br />
It is strongly recommended that you filter highly variable features (HVGs) per assay. When doing multi-group inference, you have to regress out the group effect before selecting HVGs.</p>

<p><strong>How many samples do I need?</strong><br />
Factor Analysis models are only useful with large sample sizes, at least more than 15.</p>

<p><strong>Should I remove undesired sources of variability (i.e. batch effects) before fitting the model?</strong><br />
Yes. If you have clear technical factors, we strongly encourage to regress it out a priori using a simple linear model. The reason for this is that the model will “focus” on the huge variability driven by the technical factors, and smaller sources of variability could be missed. In <code class="language-plaintext highlighter-rouge">prepare_mofa</code> there is an argument called <code class="language-plaintext highlighter-rouge">regress_covariates</code> that you can use.</p>

<p><strong>My data sets have different dimensionalities, does this matter?</strong><br />
Yes. Bigger data modalities will tend to be overrepresented in the factors. It is good practice to filter uninformative features (based for example on a minimum variance threshold) in order to have the different views within the same order of magnitudes. If this is unavoidable, take into account that the model has the risk of missing (small) sources of variation in the small data set.</p>

<p><strong>Does MOFA handle missing values?</strong><br />
Yes. It simply ignores them from the likelihood, there is no hidden imputation step. Matrix factorisation models are known to be very robust to the presence of missing values!</p>

<h2 id="faq-on-the-software">FAQ on the software</h2>

<p><strong>I get one of the following errors when running MOFA:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>AttributeError: 'module' object has no attribute 'core.entry_point

Error in py_module_import(module, convert = convert) :
 ModuleNotFoundError: No module named 'mofapy2'
</code></pre></div></div>
<p>First thing: restart R and try again. If the error still holds, this means that either you did not install the mofapy2 Python package (see instructions above), or you have multiple Python installations and R is not detecting the correct one where mofapy2 is installed. You need to find out the right Python interpreter (which usually will be the one you get when running <code class="language-plaintext highlighter-rouge">which python</code> in the terminal) and specify the following at the beginning of your R script:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>library(reticulate)
use_python("YOUR_PYTHON_PATH", required=TRUE)
</code></pre></div></div>
<p>You can also use <code class="language-plaintext highlighter-rouge">use_conda</code> instead of <code class="language-plaintext highlighter-rouge">use_python</code> if you work with conda environments. For details read more about the <a href="https://rstudio.github.io/reticulate/">reticulate</a> package.</p>

<p><strong>I get the following error when installing the R package:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ERROR: dependencies 'XXX', 'YYY' are not available for package 'MOFA2'
</code></pre></div></div>
<p>You probably tried to install them using <code class="language-plaintext highlighter-rouge">install.packages()</code>. These packages should be installed from Bioconductor.</p>

<p><strong>I hate R, can I do MOFA only with Python?</strong><br />
You can use Python to train the model, see <a href="https://github.com/bioFAM/MOFA2/blob/master/mofapy2/notebooks/getting_started_python.ipynb">this notebook</a> and <a href="https://github.com/bioFAM/MOFA2/blob/master/template_script.py">this template script</a>. However, we currently do not provide downstream analysis functions in Python (it is in our to-do list). For now we strongly recommend that you use our MOFA2 R package for this.</p>

<p><strong>Can I speed up the training procedure using CPU parallel processing?</strong> 
MOFA uses <a href="https://numpy.org/">numpy</a> for the mathematical operations. This library can be massively optimised by linking it to OpenBLAS or the Intel MKL libraries, which take advantage of multiple cores and multithreading.</p>

<p>You can check which libraries you have linked to numpy using</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python -c "import numpy; print(numpy.show_config())"
</code></pre></div></div>
<p>Note that if you are using anaconda, numpy is automatically linked to MKL (see https://docs.anaconda.com/mkl-optimizations/).<br />
The next step is to define the environmental variables. For MKL you need to set <code class="language-plaintext highlighter-rouge">MKL_NUM_THREADS=N</code> where N is the number of cores.</p>

<p><strong>How can I use GPUs to speed up training?</strong><br />
The Python core of MOFA can take advantage of NVIDIA GPUs to massively speed up training. For this you have to install and configure the <a href="https://cupy.chainer.org">CuPy package</a>, which is an open-source matrix library accelerated with NVIDIA CUDA.</p>

<h2 id="faq-on-the-multi-group-functionality">FAQ on the multi-group functionality</h2>

<p><strong>How does the multi-group inference work in MOFA+?</strong><br />
The aim of the multi-group framework is not to capture differential changes in <em>mean</em> levels between the groups (as for example when doing differential RNA expression). The goal is to compare the sources of variability that drive each group. If your aim is to find a factor that “separates” the groups, you <em>DO NOT</em> want to use the multi-group framework. In this setting, the features are centered per group before fitting the model.</p>

<p><strong>How do I define groups?</strong><br />
The selection of groups is hypothesis-driven, and typically motivated by the experimental design. There is no “right” or “wrong” definition of groups, but some definitions will be more useful than others. However, the user always needs to keep in mind that the aim of the multi-group framework is not to capture differential changes between the groups. The aim is to find out which sources of variability are shared between the different groups and which ones are exclusive to a single group. To achieve this, the group effect is regressed out from the data before fitting the model.</p>

<p><strong>How do I assess the quality/robustness of groups?</strong><br />
A quick approach to assess the validity of groups is to inspect the resulting variance explained plot. If the groups are too granular, the model will not recover significant amounts of variation. If the groups are not “interesting”, this can result in a lack of “structure” in the variance explained plot (i.e. all factors being shared across all groups). 
More computationally intensive approaches can be used to assess the robustness of groups, including cross-validation and downsampling or bootstrapping samples within groups.</p>

<h2 id="faq-on-the-model-options">FAQ on the model options</h2>

<p><strong>How many factors should I learn?</strong><br />
The optimal number of factors depends on the aim of the analysis, the dimensions of the assays, the complexity of the data, there is no simple answer. In general, if the aim is to identify the major sources of biological variation one would typically consider the top 10 factors or so. In other tasks, such as imputation of missing values, even small sources of variation can be important and hence models should be trained with a large number of factors.</p>

<p><strong>Can I include known covariates in the model?</strong><br />
We extensively tested this functionality and it was not yielding good results. The reason is that covariates are usually discrete labels that do not reflect the underlying molecular biology. For example, if you introduce age as a covariate, but the actual age is different from the molecular age, the model will simply learn a new factor that corresponds to this <em>latent</em> molecular age, and it will drop the covariate from the model.<br />
We recommend that you learn the factors in a completely unsupervised manner and then relate them to the biological covariates a posteriori (see vignettes). If your covariate of interest is an important driver of variability, do not worry, MOFA will find it!</p>

<!-- **(5.4) The factors and weights have different values between runs. Is this expected?**  
This is normal and it happens because factor analysis models are rotation invariant. This means that you can rotate your factors and your weights and still find the same solution. This implies that the signs of the weight or the factors can NOT be compared across trials, only within a trial. -->

<p><strong>What data modalities can MOFA cope with?</strong></p>
<ul>
  <li>Continuous data: modelled using a gaussian likelihood</li>
  <li>Binary data: modelled using a bernoulli likelihood</li>
  <li>Count data: using a poisson likelihood</li>
</ul>

<p>Importantly, the use of non-gaussian likelihoods require statistical approximations and are not as accurate as the gaussian likelihood. If your data can be safely transformed to match the gaussian likelihood assumptions, this is ALWAYS recommended. For example RNA-seq data is expected to be normalised and modelled with a gaussian distribution, do not input the counts directly.</p>

<p><strong>Do I need to do model selection?</strong><br />
Not anymore. In MOFA v1 we did random parameter initialisation, which led to (slightly) different solutions depending on the initial conditions. In MOFA v2 we initialise the factors using Principal Component Analysis on the concatenated data set, and the weights are initialised to zero. If using standard variational inference (not stochastic) this removes the randomness in the training algorithms.</p>


<!--       <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/bioFAM/MOFA2">MOFA2</a> is maintained by <a href="https://github.com/bioFAM">bioFAM</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer> -->

    </main>
  </body>
</html>
